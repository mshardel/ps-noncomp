---
title: "Tutorial on computing sample size for studies with expected all-or-none non-compliance and selection bias based on scenarios in Shardell and El-Kamary (2009)"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setting up

First, source the code for the three functions used in this tutorial. The function ss.noncomp() is used to compute sample size without pilot data, whereas ss.noncomp.expilot() is used when leveraging external pilot data, and ss.noncomp.inpilot() is used in the presence of internal pilot data.

```{r source.funcs}
source("ss.noncomp.R")
source("ss.noncomp.expilot.R")
source("source.noncomp.inpilot.R")
```

These function will be demonstrated for the scenarios listed in Table 1 of Shardell and El-Kamary (2009).

# Computing sample size without pilot data

The function ss.noncomp() takes as arguments the means and variances by compliance group (compliers, always takers, and never takers). For compliers, separate means are provided according to treatment assigned, which are used to compute delta, the mean difference of interest to be detected. The function also takes the compliance group proportions as arguments as well as ratio of the number of participants assigned to the treatment group to the number of participants assigned to the control group. The function can be refined for normally and Bernoulli distributed data.

Implementing the six scenarios for normal data in Table 1 of Shardell and El-Kamary (2009) for two-sided tests with default sig.level (0.05), power (0.8), and ss.ratio (1) and with no refinement:

```{r nopilot.norefine}
#scenario 1, no refinement
ss.noncomp(mu.c0=0,mu.c1=0.5, sigma.c0.sq=1.2,sigma.c1.sq=1.0, rho.a=0.25,rho.n=0.25, alternative="two.sided")

#scenario 2, no refinement
ss.noncomp(mu.c0=0,mu.c1=0.5, mu.a=1.0, mu.n=-0.5, sigma.c0.sq=1.2,sigma.c1.sq=1.0, rho.a=0.25,rho.n=0.25, alternative="two.sided")

#scenario 3, no refinement
ss.noncomp(mu.c0=0,mu.c1=0.5, mu.a=1.0, mu.n=-0.5, sigma.c0.sq=1.2,sigma.c1.sq=1.0, sigma.n.sq=1.4,sigma.a.sq=1.2, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided")

#scenario 4, no refinement
ss.noncomp(mu.c0=0,mu.c1=0.5, mu.a=0.3, mu.n=0.2, sigma.c0.sq=1.2,sigma.c1.sq=1.0, sigma.n.sq=1.2,sigma.a.sq=1.0, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided")

#scenario 5, no refinement
ss.noncomp(mu.c0=0,mu.c1=0.5, mu.a=1.5, mu.n=-1.0, sigma.c0.sq=1.2,sigma.c1.sq=1.0, sigma.n.sq=2.0,sigma.a.sq=2.0, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided")

#scenario 6, no refinement
ss.noncomp(mu.c0=0,mu.c1=0.5, mu.a=0.3, mu.n=0.2, sigma.c0.sq=1.2,sigma.c1.sq=1.0, sigma.n.sq=0.6,sigma.a.sq=0.5, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided")
```

The results of the above calculations match the "Proposed" column for normally distributed data shown in Table 2 of Shardell and El-Kamary (2009). Next, compare the calculations to those when using normal refinement:

```{r nopilot.norm.refine}
#scenario 1, normal refinement
ss.noncomp(mu.c0=0,mu.c1=0.5, sigma.c0.sq=1.2,sigma.c1.sq=1.0, rho.a=0.25,rho.n=0.25, alternative="two.sided", refinement="Normal")

#scenario 2, normal refinement
ss.noncomp(mu.c0=0,mu.c1=0.5, mu.a=1.0, mu.n=-0.5, sigma.c0.sq=1.2,sigma.c1.sq=1.0, rho.a=0.25,rho.n=0.25, alternative="two.sided", refinement="Normal")

#scenario 3, normal refinement
ss.noncomp(mu.c0=0,mu.c1=0.5, mu.a=1.0, mu.n=-0.5, sigma.c0.sq=1.2,sigma.c1.sq=1.0, sigma.n.sq=1.4,sigma.a.sq=1.2, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided", refinement="Normal")

#scenario 4, normal refinement
ss.noncomp(mu.c0=0,mu.c1=0.5, mu.a=0.3, mu.n=0.2, sigma.c0.sq=1.2,sigma.c1.sq=1.0, sigma.n.sq=1.2,sigma.a.sq=1.0, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided", refinement="Normal")

#scenario 5, normal refinement
ss.noncomp(mu.c0=0,mu.c1=0.5, mu.a=1.5, mu.n=-1.0, sigma.c0.sq=1.2,sigma.c1.sq=1.0, sigma.n.sq=2.0,sigma.a.sq=2.0, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided", refinement="Normal")

#scenario 6, normal refinement
ss.noncomp(mu.c0=0,mu.c1=0.5, mu.a=0.3, mu.n=0.2, sigma.c0.sq=1.2,sigma.c1.sq=1.0, sigma.n.sq=0.6,sigma.a.sq=0.5, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided", refinement="Normal")
```

In the six scenarios considered, normal refinement led to negligible difference in the calculated required sample size.

Lastly, implement the six scenarios for Bernoulli data in Table 1 of Shardell and El-Kamary (2009) for two-sided tests with default sig.level (0.05), power (0.8), and ss.ratio (1) and with Bernoulli refinement. Variances are not required because they are computed based on the user-inputted means (proportions):

```{r nopilot.bern.refine}
ss.noncomp(mu.c0=0.6,mu.c1=0.8, mu.a=0.8, mu.n=0.6, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided", refinement="Bernoulli")

#scenario 2, bernoulli refinement
ss.noncomp(mu.c0=0.6,mu.c1=0.8, mu.a=0.6, mu.n=0.6, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided", refinement="Bernoulli")

#scenario 3, bernoulli refinement
ss.noncomp(mu.c0=0.6,mu.c1=0.8, mu.a=0.6, mu.n=0.4, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided", refinement="Bernoulli")

#scenario 4, bernoulli refinement
ss.noncomp(mu.c0=0.6,mu.c1=0.8, mu.a=0.9, mu.n=0.8, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided", refinement="Bernoulli")

#scenario 5, bernoulli refinement
ss.noncomp(mu.c0=0.6,mu.c1=0.8, mu.a=0.2, mu.n=0.2, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided", refinement="Bernoulli")

#scenario 6, bernoulli refinement
ss.noncomp(mu.c0=0.6,mu.c1=0.8, mu.a=1.0, mu.n=1.0, 
          rho.a=0.25,rho.n=0.25, alternative="two.sided", refinement="Bernoulli")
```

The results of the above calculations match the "Proposed" column for Bernoulli distributed data shown in Table 2 of Shardell and El-Kamary (2009).

  